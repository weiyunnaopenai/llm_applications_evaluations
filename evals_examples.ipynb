{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wyn/moe_evals/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "import os\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact match evals\n",
    "Exact match evals measure whether the model‚Äôs output exactly matches a predefined correct answer. It‚Äôs a simple, unambiguous metric that‚Äôs perfect for tasks with clear-cut, categorical answers like sentiment analysis (positive, negative, neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Accuracy: 75.0%\n",
      "the model output is : ['negative', 'positive', 'mixed', 'mixed']\n",
      "the ground truth is : ['negative', 'positive', 'negative', 'mixed']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Options(str, Enum):\n",
    "    option1 = \"negative\"\n",
    "    option2 = \"positive\"\n",
    "    option3 = \"mixed\"\n",
    "    option4 = \"neutral\"\n",
    "\n",
    "\n",
    "class sentiment(BaseModel):\n",
    "    sentiment: Options\n",
    "\n",
    "\n",
    "tweets = [\n",
    "    {\"text\": \"This movie was a total waste of time. üëé\", \"sentiment\": \"negative\"},\n",
    "    {\"text\": \"The new album is üî•! Been on repeat all day.\", \"sentiment\": \"positive\"},\n",
    "    {\"text\": \"I just love it when my flight gets delayed for 5 hours. #bestdayever\", \"sentiment\": \"negative\"},  # Edge case: Sarcasm\n",
    "    {\"text\": \"The movie's plot was terrible, but the acting was phenomenal.\", \"sentiment\": \"mixed\"},  # Edge case: Mixed sentiment\n",
    "]\n",
    "\n",
    "\n",
    "def get_completion(prompt: str):\n",
    "    message = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        #max_tokens=50,\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=sentiment\n",
    "    )\n",
    "    return message.choices[0].message.parsed\n",
    "\n",
    "outputs = [get_completion(f\"Classify this as 'positive', 'negative', 'neutral', or 'mixed': {tweet['text']}\") for tweet in tweets]\n",
    "model_output =[output.sentiment.value for output in outputs]\n",
    "ground_truth = [tweet['sentiment'] for tweet in tweets]\n",
    "accuracy = sum([output == tweet for output, tweet in zip(model_output, ground_truth)]) / len(ground_truth)\n",
    "print(f\"Sentiment Analysis Accuracy: {accuracy * 100}%\")\n",
    "print(f\"the model output is : {model_output}\")\n",
    "print(f\"the ground truth is : {ground_truth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity evals\n",
    "Cosine similarity measures the similarity between two vectors (in this case, sentence embeddings of the model‚Äôs output using SBERT) by computing the cosine of the angle between them. Values closer to 1 indicate higher similarity. It‚Äôs ideal for evaluating consistency because similar questions should yield semantically similar answers, even if the wording varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cosine similarity results is : [0.57449484, 0.66036063]\n",
      "the outputs are : ['The mission of the Singapore Ministry of Education (MOE) is to mold the future of the nation by shaping the young. MOE aims to provide a well-rounded education that helps students discover their talents, pursue their interests, and reach their full potential. The Ministry focuses on nurturing a passion for learning and fostering values like resilience and responsibility to prepare individuals for the challenges of the future. Additionally, MOE is committed to working closely with educators, parents, and the community to achieve their educational goals.', \"The mission of the Inland Revenue Authority of Singapore (IRAS) is typically focused on the administration of the country's tax system. While specific wording can vary over time, generally, IRAS's mission includes objectives such as collecting taxes that are due in a fair and efficient manner, ensuring compliance with tax laws, and fostering a competitive tax environment to support the economic development of Singapore. It also often includes commitments to providing excellent service to taxpayers and leveraging technology to enhance tax administration. For the most current and specific mission statement, it would be best to refer directly to IRAS's official communications or website.\"]\n"
     ]
    }
   ],
   "source": [
    "faq_variations = [\n",
    "    {\"questions\": \"What's the mission of Singapore Ministry of Education?\", \"answer\": \"The mission of MOE is to mould the future of our nation by moulding the people who will determine our future.\"},  # Edge case: Typos\n",
    "    {\"questions\":  \"What's the mission of Singapore Inland Revenue Authority of Singapore\", \"answer\": \"Act as an agent of the Government and provide service in the administration of taxes and enterprise disbursements. Advise the Government, and represent Singapore internationally, on matters relating to taxation.\"} #{\"questions\": [\"I'm Jane's cousin, and she said you guys have great customer service. Can I return this?\", \"Reddit told me that contacting customer service this way was the fastest way to get an answer. I hope they're right! What is the return window for a jacket?\"], \"answer\": \"Our return policy allows...\"},  # Edge case: Irrelevant info\n",
    "    # ... 47 more FAQs\n",
    "]\n",
    "\n",
    "def get_completion(prompt: str):\n",
    "    message = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        #max_tokens=2048,\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.choices[0].message.content\n",
    "\n",
    "outputs = [get_completion(test[\"questions\"]) for test in faq_variations]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "cosine_similarities_results = []\n",
    "for output, faq_variation in zip(outputs, faq_variations):\n",
    "    output_embeddings = model.encode(output)\n",
    "    ground_truth_embeddings = model.encode(faq_variation['answer'])\n",
    "    cosine_similarities = np.dot(output_embeddings, ground_truth_embeddings) / (np.linalg.norm(output_embeddings) * np.linalg.norm(ground_truth_embeddings))\n",
    "    cosine_similarities_results.append(cosine_similarities)\n",
    "\n",
    "print(f\"the cosine similarity results is : {cosine_similarities_results}\")\n",
    "print(f\"the outputs are : {outputs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE-L evals\n",
    "ROUGE-L (Recall-Oriented Understudy for Gisting Evaluation - Longest Common Subsequence) evaluates the quality of generated summaries. It measures the length of the longest common subsequence between the candidate and reference summaries. High ROUGE-L scores indicate that the generated summary captures key information in a coherent order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-L F1 Score: 0.2956521689164462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "articles = [\n",
    "    {\"text\": \"\"\"The mission of MOE is to mould the future of our nation by moulding the people who will determine our future.\n",
    "The wealth of a nation lies in its people. Their commitment to country and community, their willingness to strive and persevere, their ability to think, achieve and excel. How we raise our young at home and teach them in school will shape our society in the next generation. Our future depends on the continuous renewal and regeneration of our leadership and citizenry, building upon the experience of the past, learning from the circumstances of the present, and preparing to seize the opportunities of the future.\n",
    "To achieve our mission, MOE will provide our children with a balanced and well-rounded education, develop them to their full potential, and nurture them into lifelong learners and good citizens, conscious of their responsibilities to family, community and country.\n",
    "MOE's vision of ‚ÄúThinking Schools, Learning Nation‚Äù (TSLN) was first announced by then-Prime Minister Goh Chok Tong in 1997.This vision describes a nation of thinking and committed citizens capable of seizing future opportunities, and an education system ready to ride the waves of change in the 21st century.\n",
    "Thinking Schools will be learning organisations in every sense, constantly challenging assumptions, and seeking better ways of doing things through participation, creativity and innovation. Thinking Schools will be the cradle of thinking students as well as thinking adults. This spirit of learning should accompany our students throughout their lives, even after they have graduated from the system.\n",
    "A Learning Nation envisions a national culture and social environment that promotes lifelong learning in our people. The capacity of Singaporeans to continually learn, both for professional development and for personal enrichment, will determine our collective success as a society and nation.\"\"\", \n",
    "\"summary\": \"The mission of the Singapore Ministry of Education (MOE) is to mold the future of the nation by shaping the young. MOE aims to provide a well-rounded education that helps students discover their talents, pursue their interests, and reach their full potential. The Ministry focuses on nurturing a passion for learning and fostering values like resilience and responsibility to prepare individuals for the challenges of the future. Additionally, MOE is committed to working closely with educators, parents, and the community to achieve their educational goals.\"}, \n",
    "]\n",
    "\n",
    "\n",
    "def get_completion(prompt: str):\n",
    "    message = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.choices[0].message.content   \n",
    "\n",
    "def evaluate_rouge_l(model_output, true_summary):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(model_output, true_summary)\n",
    "    return scores[0]['rouge-l']['f']  # ROUGE-L F1 score\n",
    "\n",
    "outputs = [get_completion(f\"Summarize this article in 1-2 sentences:\\n\\n{article['text']}\") for article in articles]\n",
    "relevance_scores = [evaluate_rouge_l(output, article['summary']) for output, article in zip(outputs, articles)]\n",
    "print(f\"Average ROUGE-L F1 Score: {sum(relevance_scores) / len(relevance_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
